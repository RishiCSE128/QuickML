{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuickML Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing VMWare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VMWare, or an equivalent (VirtualBox, etc.) needs to be installed to be able to run virtual envrionments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to creating a machine learning model is preparing the data to be fed into it by pre-processing. The data needs to be pre-processed and the following steps followed:\n",
    "\n",
    "1. Acquire the Dataset \n",
    "2. Import Necessary Libraries \n",
    "3. Import the Dataset\n",
    "4. Handling Missing Values\n",
    "5. Encoding Categorical Data\n",
    "6. Splitting into Training and Test Set\n",
    "7. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing All Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping independent, dependent, categorical and missing data\n",
    "# to begin data pre-processing.\n",
    "var_map = {\n",
    "    \"independent\" : [\"R&D Spend\", \"Administration\",\"Marketing Spend\", \"State\"],\n",
    "    \"dependent\" : [\"Profit\"],\n",
    "    \"categorical\" : [\"State\"],\n",
    "    \"missing\": [\"Marketing Spend\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Function \n",
    "def dataPreProcess(dataSet, varMap):\n",
    "    # Obtaining Data Set\n",
    "    data_root = pd.read_csv(dataSet)\n",
    "    data = data_root.copy()\n",
    "\n",
    "    # Splitting Dependent & Independent Variables\n",
    "    X = data[varMap['independent']]  \n",
    "    y = data[varMap['dependent']]\n",
    "\n",
    "    # Removing any missing data\n",
    "    imputer = SimpleImputer(missing_values=np.nan , strategy='mean')\n",
    "    imputer = imputer.fit(X[varMap['missing']])\n",
    "    X[varMap['missing']] =imputer.transform(X[varMap['missing']])\n",
    "\n",
    "    # Encoding Categorical Variables\n",
    "    le = LabelEncoder()\n",
    "    X[varMap['categorical']]= pd.DataFrame(le.fit_transform(X[varMap['categorical']]))\n",
    "    col_tans = make_column_transformer( \n",
    "                         (OneHotEncoder(), \n",
    "                         varMap['categorical']))\n",
    "    Xtemp2 = col_tans.fit_transform(X[varMap['categorical']])\n",
    "    # Splitting Into Train and Test Set \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3 , random_state = 0)\n",
    "\n",
    "    # Feature Scaling\n",
    "    scale_X = StandardScaler()\n",
    "    X_train.iloc[: , :] = scale_X.fit_transform(X_train.iloc[: , :])\n",
    "    X_test.iloc[: , :] = scale_X.fit_transform(X_test.iloc[: , :])\n",
    "\n",
    "    # Returns a dictionary of pre-processed data\n",
    "    return(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_train\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data processing function is responsible for taking a dataset and a mapping of dependent, independent, missing and categorical data. The dataset is split into the dependent and independent data, the missing data is taken care of, and the categorical data is encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the data is split into the test and train and it is feature scaled. The function returns a dictionary of the train and test matrices and vectors ready for a machine learning model to be fitted on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Dynamic Table Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Algorithm of choice is selected, an HTML table is dynamically created with the column names:\n",
    "1. Independent\n",
    "2. Dependent\n",
    "3. Categorical \n",
    "As well as dynamically created row names which correspond to the attributes in the inputted data set. This was done using Flask and Jinja. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the file the user submits is saved to a specific folder, effectively keeping a reference to this file to be used later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoked when user submits file - \n",
    "# creates HTML table with attributes of file\n",
    "@views.route('/', methods=['POST'])\n",
    "def upload_file():\n",
    "    \n",
    "    global filename\n",
    "    file = request.files['file']\n",
    "    \n",
    "    # Saves the file so it can be accessed later on.\n",
    "    dataSet = pd.read_csv(file)\n",
    "    file.save(os.path.join(UPLOAD_FOLDER, file.filename))\n",
    "    filename = file.filename\n",
    "\n",
    "    return render_template('home.html', attributes = list(dataSet.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    " {% for i in attributes: %}\n",
    "                <tr>\n",
    "                    <th class=\"rt\" value='{{i}}'>{{i}}</th>\n",
    "                    <td><input class='rd' type=\"radio\" name='test_{{attributes.index(i)}}' \n",
    "                               value=\"Ind\"></td>\n",
    "                    <td><input class='rd dep' type=\"radio\" name='test_{{attributes.index(i)}}'\n",
    "                               value=\"Dep\"></td>\n",
    "                    <td><input class='rd' type=\"checkbox\" value=\"Cat\"></td>\n",
    "                </tr>\n",
    "{% endfor %}\n",
    "<!-- Using Jinja python expressions can be written in html. \n",
    "    Table created dynamically using for loop. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Dynamic Creation of Variable Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of the radio buttons and checkboxes on the dynamically created table are used to create the mapping of attributes. Namely, the user selects which attributes are dependent, independent, and which are categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "function makeVarMap() {\n",
    "\n",
    "  const radioButtons = document.querySelectorAll('.rd');  // All radio buttons\n",
    "  const headers = document.querySelectorAll('th.rt');     // Headers\n",
    "  // Hard coded keys as they never change regardless of use case. \n",
    "  var varMap = {\n",
    "    'Independent': [],\n",
    "    'Dependent': [],\n",
    "    'Categorical': []\n",
    "  }\n",
    "\n",
    "  var head = [];\n",
    "  for (let i = 0; i < headers.length; ++i) {\n",
    "    head[i] = headers[i].textContent;\n",
    "  }\n",
    "  var j = 0;\n",
    "  // Loops through radio buttons \n",
    "  for (let x = 0; x < radioButtons.length; x++) {\n",
    "    if (radioButtons[x].checked && radioButtons[x].value == 'Ind') {\n",
    "      varMap['Independent'].push(head[j]);\n",
    "      j++;\n",
    "    }\n",
    "    if (radioButtons[x].checked && radioButtons[x].value == 'Dep') {\n",
    "      varMap['Dependent'].push(head[j]);\n",
    "      j++;\n",
    "    }\n",
    "    if (radioButtons[x].checked && radioButtons[x].value == 'Cat') {\n",
    "      // Decrements becase a categorical variable is always ALSO ind or dep.   \n",
    "      j--;\n",
    "      varMap['Categorical'].push(head[j]);\n",
    "      j++;\n",
    "      // Increments so order is not messed up.\n",
    "    }\n",
    "  }\n",
    "  console.log(varMap);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also some checkbox logic implemented such that a variable cannot be both independent and dependent and that there can only ever be one dependent variable in any inputted dataset. This was done in jQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "$(document).ready(function () {\n",
    "  $('input.dep:radio').change(function() {\n",
    "      // When any radio button on the page is selected,\n",
    "      // then deselect all other radio buttons.\n",
    "      $('input.dep:radio:checked').not(this).prop('checked', false);\n",
    "  });\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Passing Variable Mapping to be Pre Processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable mapping is created in JavaScript dnyamically using the users input. It is then passed to the python backend using AJAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "$.ajax({\n",
    "    url: '/dataPreProcessing',\n",
    "    type: \"POST\",\n",
    "    contentType: \"application/json\", \n",
    "    data: JSON.stringify(s)\n",
    "  }).done(function(result){     // on success get the return object from server\n",
    "    console.log(result)     // see it in the console to test its working \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Pre Processing the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the variable mapping is created in the JavaScript, it is passed into the flask backend which takes the original file the user submitted, as well as the newly created variable mapping, passing both of them as arguments to the data pre-processing function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoked when user submits variable mapping \n",
    "@views.route('/dataPreProcessing', methods=['POST'])\n",
    "def dataPre():\n",
    "    # result is the variable mapping in a JSON format\n",
    "    result =  request.get_json()\n",
    "\n",
    "    # Dataset and variable mapping to be passed into the data\n",
    "    # pre-processing function\n",
    "    varMap = json.loads(result)\n",
    "    file = os.path.join(UPLOAD_FOLDER, filename)\n",
    "\n",
    "    table = DPP.dataPreProcess(file, varMap)\n",
    "\n",
    "    # Getting the individual components of pre processed data \n",
    "    # to keep a reference to them for when they need to be passed \n",
    "    # in to the selected algorithm.\n",
    "    xTest = pd.DataFrame(table['X_test'])\n",
    "    xTrain = pd.DataFrame(table['X_train'])\n",
    "    yTest = pd.DataFrame(table['y_test'])\n",
    "    yTrain = pd.DataFrame(table['y_train'])   \n",
    "\n",
    "    # Creating variables to store file names and locations for pre \n",
    "    # processed data locations\n",
    "    fN_xT = '/home/user/Documents/git/QuickML/pre_processed_data/xTest'\n",
    "    fN_xTr = '/home/user/Documents/git/QuickML/pre_processed_data/xTrain'\n",
    "    fN_yT = '/home/user/Documents/git/QuickML/pre_processed_data/yTest'\n",
    "    fN_yTr = '/home/user/Documents/git/QuickML/pre_processed_data/yTrain'\n",
    "\n",
    "    # pd.to_csv creates the file if it does not exist, but it does not \n",
    "    # create any non existent directories. The pre_processed_data directory \n",
    "    # already exists, pd.to_csv <i>creates</i> the files and populates them \n",
    "    # with the contents of their respective components. \n",
    "    xTest.to_csv(fN_xT)\n",
    "    xTrain.to_csv(fN_xTr)\n",
    "    yTest.to_csv(fN_yT)\n",
    "    yTrain.to_csv(fN_yTr)\n",
    "\n",
    "    # Getting the file out of the whole path and converting it to a dataframe.\n",
    "    dF = pd.read_csv(file.split('/')[-1])\n",
    "    \n",
    "    # Columns still hard coded! Fix before deploying to production. \n",
    "    col = dF.columns\n",
    "\n",
    "    # return formattes string which contains HTML and HTML tables using \n",
    "    # the 'tabulate' module\n",
    "    return (f'''\n",
    "            <h2 style=\"text-align:center\">Scroll to Preview your Pre-Processed Data!</h2>\n",
    "            <hr>\n",
    "            <div>\n",
    "                <h3 style=\"text-align:left\"> X train </h3> \n",
    "                <h3 style=\"text-align:right; margin-top:-40px\"> Y train </h3> <hr><br>\n",
    "                <div class=\"container\" style=\"display:flex; width=70%\">\n",
    "                    {tabulate(table['X_train'], tablefmt='html', headers = col)}\n",
    "                    {tabulate(table['y_train'], tablefmt='html', headers = col[4:])}\n",
    "                </div>\n",
    "                <hr>\n",
    "                <h3 style=\"text-align:left\"> X test </h3> \n",
    "                <h3 style=\"text-align:right; margin-top:-40px\"> Y test </h3> <hr><br>\n",
    "                <div class=\"container\" style=\"display:flex; width=70%\">\n",
    "                    {tabulate(table['X_test'], tablefmt='html', headers = col)}\n",
    "                    {tabulate(table['y_test'], tablefmt='html', headers = col[4:])}\n",
    "                </div>\n",
    "            </div>\n",
    "    ''' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also writed 4 csv files each containing one of the components of the pre-processed data:\n",
    "1. X_train\n",
    "2. y_train \n",
    "\n",
    "These are datasets which will be used to train the Machine Learning/Deep Learning model. \n",
    "\n",
    "3. X_test\n",
    "4. y_train\n",
    "\n",
    "These are the datasets which are given to the ML/DL model to test it's accruacy. Based on these results, the confusion matrix is created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fitting the Correct Algorithm "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41521eb1593546d57655f2f56fbdac702f45c11c5d7823438dfc04eb3b8fc312"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
