{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuickML Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing VMWare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VMWare, or an equivalent (VirtualBox, etc.) needs to be installed to be able to run virtual envrionments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to creating a machine learning model is preparing the data to be fed into it by pre-processing. The data needs to be pre-processed and the following steps followed:\n",
    "\n",
    "1. Acquire the Dataset \n",
    "2. Import Necessary Libraries \n",
    "3. Import the Dataset\n",
    "4. Handling Missing Values\n",
    "5. Encoding Categorical Data\n",
    "6. Splitting into Training and Test Set\n",
    "7. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing All Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping independent, dependent, categorical and missing data\n",
    "# to begin data pre-processing.\n",
    "var_map = {\n",
    "    \"independent\" : [\"R&D Spend\", \"Administration\",\"Marketing Spend\", \"State\"],\n",
    "    \"dependent\" : [\"Profit\"],\n",
    "    \"categorical\" : [\"State\"],\n",
    "    \"missing\": [\"Marketing Spend\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Function \n",
    "def dataPreProcess(dataSet, varMap):\n",
    "    # Obtaining Data Set\n",
    "    data_root = pd.read_csv(dataSet)\n",
    "    data = data_root.copy()\n",
    "\n",
    "    # Splitting Dependent & Independent Variables\n",
    "    X = data[varMap['independent']]  \n",
    "    y = data[varMap['dependent']]\n",
    "\n",
    "    # Removing any missing data\n",
    "    imputer = SimpleImputer(missing_values=np.nan , strategy='mean')\n",
    "    imputer = imputer.fit(X[varMap['missing']])\n",
    "    X[varMap['missing']] =imputer.transform(X[varMap['missing']])\n",
    "\n",
    "    # Encoding Categorical Variables\n",
    "    le = LabelEncoder()\n",
    "    X[varMap['categorical']]= pd.DataFrame(le.fit_transform(X[varMap['categorical']]))\n",
    "    col_tans = make_column_transformer( \n",
    "                         (OneHotEncoder(), \n",
    "                         varMap['categorical']))\n",
    "    Xtemp2 = col_tans.fit_transform(X[varMap['categorical']])\n",
    "    # Splitting Into Train and Test Set \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3 , random_state = 0)\n",
    "\n",
    "    # Feature Scaling\n",
    "    scale_X = StandardScaler()\n",
    "    X_train.iloc[: , :] = scale_X.fit_transform(X_train.iloc[: , :])\n",
    "    X_test.iloc[: , :] = scale_X.fit_transform(X_test.iloc[: , :])\n",
    "\n",
    "    # Returns a dictionary of pre-processed data\n",
    "    return(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_train\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data processing function is responsible for taking a dataset and a mapping of dependent, independent, missing and categorical data. The dataset is split into the dependent and independent data, the missing data is taken care of, and the categorical data is encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the data is split into the test and train and it is feature scaled. The function returns a dictionary of the train and test matrices and vectors ready for a machine learning model to be fitted on. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41521eb1593546d57655f2f56fbdac702f45c11c5d7823438dfc04eb3b8fc312"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
